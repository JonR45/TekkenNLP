{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda2f52-4dbe-4186-b1bd-a9f7966feb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f921a-870a-4a6c-9a09-fea1c15889d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # this resolves ImportError: attempted relative import with no known parent package\n",
    "\n",
    "# general DS packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# cleaning and pre-processing\n",
    "from src.processing.text_cleaning import normalize_text, process_contractions, remove_all_punctuation, remove_emojis, remove_html_unescape, remove_digits, remove_extra_whitespace, remove_website_links\n",
    "from src.processing.text_processing import tokenize_comment, lemmatize_comment, remove_stop_words, part_of_speech, part_of_speech_tag, part_of_speech_dependency, part_of_speech_shape, part_of_speech_alpha, part_of_speech_is_stop\n",
    "\n",
    "# modeling\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# visualisation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e164f05-1332-4e94-a6ca-4944b37c4df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import data from csv\n",
    "raw_data = pd.read_csv(\"data/raw/new_character_reveal_comments.csv\", )\n",
    "data = raw_data.copy()\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141cfccd-313a-43fc-aafa-5d84d2c5283a",
   "metadata": {},
   "source": [
    "# Clean and process dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55b79d-44f3-4725-adab-d10c72c33fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# clean\n",
    "df['textDisplay'] = df['textDisplay'].apply(normalize_text)\n",
    "df['textDisplay'] = df['textDisplay'].apply(process_contractions)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_website_links)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_html_unescape)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_emojis)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_digits)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_all_punctuation)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_extra_whitespace)\n",
    "\n",
    "# process\n",
    "df[\"textStopWordsRemoved\"] = df[\"textDisplay\"].apply(remove_stop_words)\n",
    "df[\"textTokenized\"] = df['textStopWordsRemoved'].apply(tokenize_comment)\n",
    "df[\"textLemmatized\"] = df[\"textStopWordsRemoved\"].apply(lemmatize_comment)\n",
    "\n",
    "# part of speech operations\n",
    "df[\"pos\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech)\n",
    "df[\"posTag\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_tag)\n",
    "df[\"posDependency\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_dependency)\n",
    "df[\"posShape\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_shape)\n",
    "df[\"posAlpha\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_alpha)\n",
    "df[\"posStopWord\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_is_stop)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e516cb3f-5a9c-4a46-b226-7b737151bc3e",
   "metadata": {},
   "source": [
    "# Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b6c33-ba00-4753-9284-f5cc7c9e1834",
   "metadata": {},
   "source": [
    "## Create corpus and document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ce93b-957b-4554-86fd-ba3c95964730",
   "metadata": {},
   "source": [
    "Create a corpus (a list that contains all of the YouTube comments in it))..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a812c5-1ebb-4746-8b63-438b442d1213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a corpus\n",
    "corpus = list(df['textLemmatized'].values)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac9ea2-bf34-4aeb-9aae-a7a480770a9a",
   "metadata": {},
   "source": [
    "Use Gensim to create a dictionary that will store each word in the corpus and assign a unique ID to it. Then create a bag of words document-term matrix which will return a tuple with the word's unique ID and how many times it occurs in the document i.e., (word_id, frequnecy_in_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c0962-decb-4199-ae86-7091a0922538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "comments_dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "# create term document frequency\n",
    "document_term_matrix = [comments_dictionary.doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e66c4-2870-43fd-9565-e0ae101b711b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad6400-fb0d-4cd0-8baf-454170c6edf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c767d8-720b-4f93-95dc-77fde7cea22a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The document term matrix is a list and each document (YouTube comment) within the list is now a list of tuples instead of tokens (words). The tuples provide the word ID (each word has a unique ID created by Gensim) and the frequency with which that word occurs in the document.\n",
    "\n",
    "\n",
    "We can also view the actual word with the frequency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db5dd4-7970-419f-a380-bfbaefd3c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ddc531-ae8a-445c-9e0e-22659bcdd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human readable format of document term matrix for first youtube comments\n",
    "[[(comments_dictionary[id], freq) for id, freq in cp] for cp in document_term_matrix[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b89cd9-f31c-4c55-a592-45299218c23c",
   "metadata": {},
   "source": [
    "We now have the data in a state where we can build the topic model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f384fa-97d1-4f74-8472-30015cb6f273",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75463b-b372-4ebb-a820-3bd2cd2725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097c218-1898-40f9-8949-46d39b519e36",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadac973-b6c2-4e09-b79d-7a28bfe67ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model\n",
    "lda_number_of_topics = 3\n",
    "lda_model = LdaModel(corpus=document_term_matrix,\n",
    "                     num_topics=lda_number_of_topics, \n",
    "                     id2word=comments_dictionary,\n",
    "                     passes=10,   # number of iterations over the entire corpus during model training\n",
    "                    random_state=42,)\n",
    "\n",
    "# Results\n",
    "lda_model.print_topics(num_topics=lda_number_of_topics, num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0239678-c6c3-45e5-842a-c392d41a7beb",
   "metadata": {},
   "source": [
    "### Visualise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8da46-bd3e-4c65-8a79-4245e584eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, document_term_matrix, comments_dictionary)\n",
    "pyLDAvis.save_html(vis, \"visualisations/lda_topics_viz.html\")\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c879bc6-61a2-4912-a7f3-30491cce071d",
   "metadata": {},
   "source": [
    "### How to interpret pyLDAvisâ€™s output?\n",
    "\n",
    "- Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "- A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "- A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
    "- If you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c4318-d062-4d55-afbe-902a76152eb8",
   "metadata": {},
   "source": [
    "## Perplexity and coherence\n",
    "- Model perplexity and topic coherence provide a convenient measure to indicate how good a given topic model is.\n",
    "- Lower the perplexity better the model.\n",
    "- Higher the topic coherence, the topic is more human interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b5c3f-b2bf-4fbe-b431-145946f98d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Perplexity\n",
    "print(f\"\\nPerplexity: ' {lda_model.log_perplexity(chunk=document_term_matrix, total_docs=None)}\")   # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus, dictionary=comments_dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"\\nCoherence Score: ' {coherence_lda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947a0d5-ea83-4bff-abba-1676700091c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac444dc-1a87-47fd-aee1-d496162cb975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "352ac4fc-3f66-43ea-8262-fcd45635a1b3",
   "metadata": {},
   "source": [
    "# LDA: bigram and trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b101a-1b0d-413d-a8ce-569807b4fd1b",
   "metadata": {},
   "source": [
    "### Build the bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462c265-c1ea-4c2d-8c96-29b5d9b8bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(corpus, min_count=3, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[corpus], threshold=10)  \n",
    "\n",
    "# Phraser objects take Phrases models as inputs and are optimized for faster phrase application\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[corpus[0]]])   # applies the bigram model to the first document, combining common word pairs. trigram_mod[] applies the trigram model \n",
    "                                            # to the result of the bigram application, forming trigrams from frequent bigrams and single words.\n",
    "print(trigram_mod[bigram_mod[corpus[135]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad6e4f8-7c8e-48b4-a7ef-16c49af3a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(corpus):\n",
    "    return [bigram_mod[doc] for doc in corpus]\n",
    "\n",
    "def make_trigrams(corpus):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ceb33-3031-42f2-b1fe-8a170a077699",
   "metadata": {},
   "source": [
    "### Create bigrams corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c97de8-c9fb-4357-89c7-71f480421276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bigrams corpus\n",
    "corpus_bigrams = make_bigrams(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65b473-288d-47aa-83d3-9031989e3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "bigrams_dictionary = corpora.Dictionary(corpus_bigrams)\n",
    "\n",
    "# create term document frequency\n",
    "bigrams_document_term_matrix = [bigrams_dictionary.doc2bow(doc) for doc in corpus_bigrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b636d-13a5-46d9-9a7c-bdeba6a86d42",
   "metadata": {},
   "source": [
    "### Create bigrams model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ce924-2aef-4b1c-9bf6-8766630ac478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model\n",
    "lda_number_of_topics = 3\n",
    "lda_bigrams_model = LdaModel(corpus=bigrams_document_term_matrix,\n",
    "                     num_topics=lda_number_of_topics, \n",
    "                     id2word=bigrams_dictionary,\n",
    "                     passes=10,   # number of iterations over the entire corpus during model training\n",
    "                    random_state=42,)\n",
    "\n",
    "# Results\n",
    "lda_bigrams_model.print_topics(num_topics=lda_number_of_topics, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dde4f2-02b6-442b-9613-0ad561d3fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_bigrams_model, bigrams_document_term_matrix, bigrams_dictionary)\n",
    "pyLDAvis.save_html(vis, \"visualisations/lda_bigrams_topics_viz.html\")\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e26a41-b642-4189-afea-4a4adb59f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Perplexity\n",
    "print(f\"\\nPerplexity: ' {lda_bigrams_model.log_perplexity(chunk=bigrams_document_term_matrix, total_docs=None)}\")   # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda_bigrams = CoherenceModel(model=lda_bigrams_model, texts=corpus_bigrams, dictionary=bigrams_dictionary, coherence='c_v')\n",
    "coherence_lda_bigrams = coherence_model_lda_bigrams.get_coherence()\n",
    "print(f\"\\nCoherence Score: ' {coherence_lda_bigrams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a84da-ddb9-4820-be03-967d3150ed6d",
   "metadata": {},
   "source": [
    "The bigrams model is more perplex and coherent. This means:\n",
    "- The model is able to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acbc14-8dc5-4c4b-9737-3886d29c40cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee42a2-aa50-4414-b42a-cd616d0d4690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55a67c-a09a-465e-939e-61e725f7e575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "936da200-e0ab-4c28-a3c3-9de766ac740d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Next steps\n",
    "- BERT model\n",
    "- Non negative matrix/explore other models that may be suitable\n",
    "- try one where you remove all words apart from character names?\n",
    "- Wordcloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d224850-dc82-4501-808a-70b9735170cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f78bdd-171a-4fdc-a728-c263748f2360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc4320-21ed-4d19-9f74-ffde14937d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829ed6a-5a7e-4b53-8817-68aa60bc190c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f494d-ac74-4eb6-a320-95b75ef3d914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396b4d5-8250-402c-970f-7de9621cd33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c519426-1ec8-494b-8ccf-bf9e4fbf7f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3690d47-24ef-4ef8-b019-995b78b312b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d70043-ebd3-429c-8506-00d363368282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
