{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355a62b6-0438-43f3-8f5c-601117a5c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # this resolves ImportError: attempted relative import with no known parent package\n",
    "\n",
    "# general DS packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "\n",
    "# cleaning and pre-processing\n",
    "from src.processing.text_cleaning import (normalize_text, process_contractions, remove_all_punctuation, remove_emojis, \n",
    "remove_html_unescape, remove_href_pattern, remove_digits, remove_extra_whitespace, remove_website_links)\n",
    "\n",
    "from src.processing.text_processing import (tokenize_comment, lemmatize_comment, remove_stop_words, remove_tiny_tokens, \n",
    "remove_tekken_character_names_from_tokens, part_of_speech, part_of_speech_tag, part_of_speech_dependency, part_of_speech_shape, \n",
    "part_of_speech_alpha, part_of_speech_is_stop, word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f96fb4-4379-4490-a70c-184474d202a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from csv\n",
    "raw_data = pd.read_csv(\"data/raw/new_character_reveal_comments.csv\", )\n",
    "data = raw_data.copy()\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e07576c-fa6b-4ec7-9130-21d7ad581812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.5 s, sys: 92.3 ms, total: 35.6 s\n",
      "Wall time: 35.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "      <th>textDispalyWordCount</th>\n",
       "      <th>textStopWordsRemoved</th>\n",
       "      <th>textTokenized</th>\n",
       "      <th>textLemmatized</th>\n",
       "      <th>textTekkenCharactersRemoved</th>\n",
       "      <th>textProcessed</th>\n",
       "      <th>pos</th>\n",
       "      <th>posTag</th>\n",
       "      <th>posDependency</th>\n",
       "      <th>posShape</th>\n",
       "      <th>posAlpha</th>\n",
       "      <th>posStopWord</th>\n",
       "      <th>textDisplayWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>already seen it you are getting less views now...</td>\n",
       "      <td>10</td>\n",
       "      <td>seen getting views bamco</td>\n",
       "      <td>[seen, getting, views, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "      <td>see get view bamco</td>\n",
       "      <td>[VERB, VERB, NOUN, NOUN]</td>\n",
       "      <td>[VBN, VBG, NNS, NNS]</td>\n",
       "      <td>[ROOT, xcomp, dobj, dobj]</td>\n",
       "      <td>[xxxx, xxxx, xxxx, xxxx]</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "      <td>1</td>\n",
       "      <td>wow</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>wow</td>\n",
       "      <td>[INTJ]</td>\n",
       "      <td>[UH]</td>\n",
       "      <td>[ROOT]</td>\n",
       "      <td>[xxx]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>2</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP]</td>\n",
       "      <td>[compound, ROOT]</td>\n",
       "      <td>[xxx, xxxx]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[False, False]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>i hope we get an angel version of jin</td>\n",
       "      <td>9</td>\n",
       "      <td>hope angel version jin</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, version]</td>\n",
       "      <td>hope version</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[compound, compound, compound, ROOT]</td>\n",
       "      <td>[xxxx, xxxx, xxxx, xxx]</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@kazamataurus337</td>\n",
       "      <td>2023-11-01 16:10:08+00:00</td>\n",
       "      <td>2023-11-01 16:10:08+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>so it begins</td>\n",
       "      <td>3</td>\n",
       "      <td>begins</td>\n",
       "      <td>[begins]</td>\n",
       "      <td>[begin]</td>\n",
       "      <td>[begin]</td>\n",
       "      <td>begin</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>[VBZ]</td>\n",
       "      <td>[ROOT]</td>\n",
       "      <td>[xxxx]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "1  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "3  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @kazamataurus337  2023-11-01 16:10:08+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:05+00:00          1                1   \n",
       "1  2023-11-01 16:10:05+00:00          0                0   \n",
       "2  2023-11-01 16:10:06+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00        135               14   \n",
       "4  2023-11-01 16:10:08+00:00          1                0   \n",
       "\n",
       "                                         textDisplay  textDispalyWordCount  \\\n",
       "0  already seen it you are getting less views now...                    10   \n",
       "1                                                wow                     1   \n",
       "2                                          oww yeaah                     2   \n",
       "3              i hope we get an angel version of jin                     9   \n",
       "4                                       so it begins                     3   \n",
       "\n",
       "       textStopWordsRemoved                  textTokenized  \\\n",
       "0  seen getting views bamco  [seen, getting, views, bamco]   \n",
       "1                       wow                          [wow]   \n",
       "2                 oww yeaah                   [oww, yeaah]   \n",
       "3    hope angel version jin    [hope, angel, version, jin]   \n",
       "4                    begins                       [begins]   \n",
       "\n",
       "                textLemmatized textTekkenCharactersRemoved  \\\n",
       "0      [see, get, view, bamco]     [see, get, view, bamco]   \n",
       "1                        [wow]                       [wow]   \n",
       "2                 [oww, yeaah]                [oww, yeaah]   \n",
       "3  [hope, angel, version, jin]             [hope, version]   \n",
       "4                      [begin]                     [begin]   \n",
       "\n",
       "        textProcessed                           pos                posTag  \\\n",
       "0  see get view bamco      [VERB, VERB, NOUN, NOUN]  [VBN, VBG, NNS, NNS]   \n",
       "1                 wow                        [INTJ]                  [UH]   \n",
       "2           oww yeaah                [PROPN, PROPN]            [NNP, NNP]   \n",
       "3        hope version  [PROPN, PROPN, PROPN, PROPN]  [NNP, NNP, NNP, NNP]   \n",
       "4               begin                        [VERB]                 [VBZ]   \n",
       "\n",
       "                          posDependency                  posShape  \\\n",
       "0             [ROOT, xcomp, dobj, dobj]  [xxxx, xxxx, xxxx, xxxx]   \n",
       "1                                [ROOT]                     [xxx]   \n",
       "2                      [compound, ROOT]               [xxx, xxxx]   \n",
       "3  [compound, compound, compound, ROOT]   [xxxx, xxxx, xxxx, xxx]   \n",
       "4                                [ROOT]                    [xxxx]   \n",
       "\n",
       "                   posAlpha                   posStopWord  \\\n",
       "0  [True, True, True, True]  [False, False, False, False]   \n",
       "1                    [True]                       [False]   \n",
       "2              [True, True]                [False, False]   \n",
       "3  [True, True, True, True]  [False, False, False, False]   \n",
       "4                    [True]                       [False]   \n",
       "\n",
       "   textDisplayWordCount  \n",
       "0                    10  \n",
       "1                     1  \n",
       "2                     2  \n",
       "3                     9  \n",
       "4                     3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# clean\n",
    "df['textDisplay'] = df['textDisplay'].apply(normalize_text)\n",
    "df['textDisplay'] = df['textDisplay'].apply(process_contractions)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_website_links)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_html_unescape)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_emojis)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_digits)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_all_punctuation)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_href_pattern)\n",
    "df['textDisplay'] = df['textDisplay'].apply(remove_extra_whitespace)\n",
    "\n",
    "# process\n",
    "df[\"textDisplayWordCount\"] = df['textDisplay'].apply(word_count)\n",
    "df[\"textStopWordsRemoved\"] = df[\"textDisplay\"].apply(remove_stop_words)\n",
    "df[\"textTokenized\"] = df['textStopWordsRemoved'].apply(tokenize_comment)\n",
    "df[\"textLemmatized\"] = df[\"textStopWordsRemoved\"].apply(lemmatize_comment)\n",
    "# remove short meaningless tokens from lemmatized tokens\n",
    "df[\"textLemmatized\"] = df['textLemmatized'].apply(remove_tiny_tokens)\n",
    "df[\"textTekkenCharactersRemoved\"] = df[\"textLemmatized\"].apply(remove_tekken_character_names_from_tokens)\n",
    "df[\"textProcessed\"] = df[\"textTekkenCharactersRemoved\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# part of speech operations\n",
    "df[\"pos\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech)\n",
    "df[\"posTag\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_tag)\n",
    "df[\"posDependency\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_dependency)\n",
    "df[\"posShape\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_shape)\n",
    "df[\"posAlpha\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_alpha)\n",
    "df[\"posStopWord\"] = df[\"textStopWordsRemoved\"].apply(part_of_speech_is_stop)\n",
    "\n",
    "\n",
    "# remove rows with empty strings in the 'textProcessed' column as these will have nothing to pass to the vectorizer when we come to transforming the text input\n",
    "# to numerical input\n",
    "df = df[df[\"textProcessed\"].astype(str) != '']\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338f9b53-f8b6-48ea-a711-d14537e0b2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1769.000000\n",
       "mean       11.573770\n",
       "std        25.535804\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         8.000000\n",
       "75%        13.000000\n",
       "max       960.000000\n",
       "Name: textDisplayWordCount, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"textDisplayWordCount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87175032-b714-4596-930d-3cfd737d75e8",
   "metadata": {},
   "source": [
    "## Visualise top 20 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccf143-5399-43bd-b5ad-94411420752a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
