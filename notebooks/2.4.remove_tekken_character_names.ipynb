{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9976d3c9-fe21-4d5c-af0b-9cc547d7704a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # this resolves ImportError: attempted relative import with no known parent package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from src.processing.text_cleaning import normalize_text, process_contractions, remove_all_punctuation, remove_emojis, remove_html_unescape, remove_digits\n",
    "from src.processing.text_processing import tokenize_comment, lemmatize_comment, remove_stop_words\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c647d7-02d8-4751-95c2-c6c3253baae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>First. Now where is LEI WULONG?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Already seen it. Ur getting less view&amp;#39;s now bamco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oww yeaah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>I hope we get an angel version of Jin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                             textDisplay  \n",
       "0                       First. Now where is LEI WULONG?!  \n",
       "1  Already seen it. Ur getting less view&#39;s now bamco  \n",
       "2                                                    wow  \n",
       "3                                              Oww yeaah  \n",
       "4                  I hope we get an angel version of Jin  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data from csv\n",
    "raw_data = pd.read_csv(\"data/raw/new_character_reveal_comments.csv\")\n",
    "data = raw_data.copy()\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04573f86-649b-48f0-8bbe-db501bacfb9a",
   "metadata": {},
   "source": [
    "### Clean comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb17a68-b6dd-4044-a4ab-deeb06663dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9da5933-a31c-418a-b309-1710dd1981f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>First. Now where is LEI WULONG?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Already seen it. Ur getting less view&amp;#39;s now bamco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oww yeaah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>I hope we get an angel version of Jin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                             textDisplay  \n",
       "0                       First. Now where is LEI WULONG?!  \n",
       "1  Already seen it. Ur getting less view&#39;s now bamco  \n",
       "2                                                    wow  \n",
       "3                                              Oww yeaah  \n",
       "4                  I hope we get an angel version of Jin  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df.copy()\n",
    "# clean the text\n",
    "df_cleaned['textDisplay'] = df_cleaned['textDisplay'].apply(remove_html_unescape)\n",
    "df_cleaned['textDisplay'] = df_cleaned['textDisplay'].apply(remove_emojis)\n",
    "df_cleaned['textDisplay'] = df_cleaned['textDisplay'].apply(remove_all_punctuation)\n",
    "df_cleaned['textDisplay'] = df_cleaned['textDisplay'].apply(process_contractions)\n",
    "df_cleaned['textDisplay'] = df_cleaned['textDisplay'].apply(normalize_text)\n",
    "df_cleaned['textDisplay'] = df_cleaned['textDisplay'].apply(remove_digits)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24abf0c5-5643-4a72-ae70-bac15a06f4a1",
   "metadata": {},
   "source": [
    "### Process comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee2d3c6-23cb-4211-bdaa-a685c5ae5a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "      <th>textStopWordsRemoved</th>\n",
       "      <th>textTokenized</th>\n",
       "      <th>textLemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>first now where is lei wulong</td>\n",
       "      <td>lei wulong</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>already seen it you are getting less views now bamco</td>\n",
       "      <td>seen getting views bamco</td>\n",
       "      <td>[seen, getting, views, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "      <td>wow</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>i hope we get an angel version of jin</td>\n",
       "      <td>hope angel version jin</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                            textDisplay  \\\n",
       "0                         first now where is lei wulong   \n",
       "1  already seen it you are getting less views now bamco   \n",
       "2                                                   wow   \n",
       "3                                             oww yeaah   \n",
       "4                 i hope we get an angel version of jin   \n",
       "\n",
       "       textStopWordsRemoved                  textTokenized  \\\n",
       "0                lei wulong                  [lei, wulong]   \n",
       "1  seen getting views bamco  [seen, getting, views, bamco]   \n",
       "2                       wow                          [wow]   \n",
       "3                 oww yeaah                   [oww, yeaah]   \n",
       "4    hope angel version jin    [hope, angel, version, jin]   \n",
       "\n",
       "                textLemmatized  \n",
       "0                [lei, wulong]  \n",
       "1      [see, get, view, bamco]  \n",
       "2                        [wow]  \n",
       "3                 [oww, yeaah]  \n",
       "4  [hope, angel, version, jin]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words, tokenize, and lemmatize the text\n",
    "df_processed = df_cleaned.copy()\n",
    "df_processed[\"textStopWordsRemoved\"] = df_processed[\"textDisplay\"].apply(remove_stop_words)\n",
    "df_processed[\"textTokenized\"] = df_processed['textStopWordsRemoved'].apply(tokenize_comment)\n",
    "df_processed[\"textLemmatized\"] = df_processed[\"textStopWordsRemoved\"].apply(lemmatize_comment)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989288ed-9526-4c92-ad1c-cde0d25216af",
   "metadata": {},
   "source": [
    "# remove character names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8542ad5c-32d0-45b0-bb04-97f335f1665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "      <th>textStopWordsRemoved</th>\n",
       "      <th>textTokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>first now where is lei wulong</td>\n",
       "      <td>lei wulong</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>already seen it you are getting less views now bamco</td>\n",
       "      <td>seen getting views bamco</td>\n",
       "      <td>[seen, getting, views, bamco]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "      <td>wow</td>\n",
       "      <td>[wow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>i hope we get an angel version of jin</td>\n",
       "      <td>hope angel version jin</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                            textDisplay  \\\n",
       "0                         first now where is lei wulong   \n",
       "1  already seen it you are getting less views now bamco   \n",
       "2                                                   wow   \n",
       "3                                             oww yeaah   \n",
       "4                 i hope we get an angel version of jin   \n",
       "\n",
       "       textStopWordsRemoved                  textTokenized  \n",
       "0                lei wulong                  [lei, wulong]  \n",
       "1  seen getting views bamco  [seen, getting, views, bamco]  \n",
       "2                       wow                          [wow]  \n",
       "3                 oww yeaah                   [oww, yeaah]  \n",
       "4    hope angel version jin    [hope, angel, version, jin]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5805e-7108-4a85-8412-fa202c93fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tekken_8_characters = [\n",
    "\"Alisa Bosconovich\", \"Asuka Kazama\", \"Azucena Ortiz (New)\", \"Bryan Fury\", \"Claudio Serafino\", \"Devil Jin\",\n",
    "\"Feng Wei\", \"Hwoarang\", \"Jack-8\", \"Jin Kazama\", \"Jun Kazama\", \"Kazuya Mishima\", \"King\", \"Kuma\", \"Lars Alexandersson\",\n",
    "\"Lee Chaolan\", \"Leo Kliesen\", \"Leroy Smith\", \"Lili De Rochefort\", \"Ling Xiaoyu\", \"Marshall Law\", \"Nina Williams\",\n",
    "\"Panda\", \"Raven\", \"Reina (New)\", \"Sergei Dragunov\", \"Shaheen\", \"Steve Fox\", \"Victor Chevalier (New)\", \"Yoshimitsu\",\n",
    "\"Zafina\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "178e5f85-3eb6-4caf-b38a-48f8cb25b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tekken_characters = ['Alex', 'Alisa Bosconovich', 'Angel', 'Anna Williams', 'Armor King', 'Asuka Kazama', \n",
    "                         'Ayane', 'Azazel', 'Baek Doo San', 'Bruce Irvin', 'Bryan Fury', 'Christie Monteiro', \n",
    "                         'Claudio Serafino', 'Combot', 'Cyclops', 'Debug', \n",
    "                         'Devil Jin', 'Eddy Gordo', 'Eliza', 'Feng Wei', 'Forest Law', 'Ganryu', 'Gigas', \n",
    "                         'Gon', 'Heihachi Mishima', 'Hwoarang', 'Jack', 'Jack-7', 'Jack-8', 'Jin Kazama', 'Julia Chang', \n",
    "                         'Jun Kazama', 'Kazumi Mishima', 'King', 'Kuma', 'Kunimitsu', 'Doctor Bosconovitch', \n",
    "                         'Dragunov, Sergei', 'Eddy Gordo', 'Fahkumram', 'Geese Howard', 'Jinpachi Mishima', 'Josie Rizal', \n",
    "                         'Katarina Alves', 'Lee Chaolan', 'Leo Kliesen', 'Lili De Rochefort', 'Ling Xiaoyu', 'Lucky Chloe', 'Leroy Smith', \n",
    "                         'Lidia Sobieska', 'Master Raven', 'Michelle Chang', 'Miguel Rojo', 'Mokujin', 'Nancy-MI847J', \n",
    "                         'Negan', 'Nina Williams', 'Noctis', 'Ogre', 'True Ogre', \n",
    "                         'Marshall Law', 'Panda', 'Paul Phoenix', 'Rachel', 'Roger Jr', \"Sake\", \n",
    "                         'Steve Fox', 'Tekken Force Soldier', \n",
    "                         \"Violet\", 'Wang Jinrei', 'Yoshimitsu', 'Zafina', 'Azucena Ortiz', 'Reina', 'Victor Chevalier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca9f728f-568e-42fe-88e8-7234421ecf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alex', 'Alisa Bosconovich', 'Angel', 'Anna Williams', 'Armor King', 'Asuka Kazama', 'Ayane', 'Azazel', 'Azucena Ortiz', 'Baek Doo San', 'Bruce Irvin', 'Bryan Fury', 'Christie Monteiro', 'Claudio Serafino', 'Combot', 'Cyclops', 'Debug', 'Devil Jin', 'Doctor Bosconovitch', 'Dragunov, Sergei', 'Eddy Gordo', 'Eddy Gordo', 'Eliza', 'Fahkumram', 'Feng Wei', 'Forest Law', 'Ganryu', 'Geese Howard', 'Gigas', 'Gon', 'Heihachi Mishima', 'Hwoarang', 'Jack', 'Jack-7', 'Jack-8', 'Jin Kazama', 'Jinpachi Mishima', 'Josie Rizal', 'Julia Chang', 'Jun Kazama', 'Katarina Alves', 'Kazumi Mishima', 'King', 'Kuma', 'Kunimitsu', 'Lee Chaolan', 'Leo Kliesen', 'Leroy Smith', 'Lidia Sobieska', 'Lili De Rochefort', 'Ling Xiaoyu', 'Lucky Chloe', 'Marshall Law', 'Master Raven', 'Michelle Chang', 'Miguel Rojo', 'Mokujin', 'Nancy-MI847J', 'Negan', 'Nina Williams', 'Noctis', 'Ogre', 'Panda', 'Paul Phoenix', 'Rachel', 'Reina', 'Roger Jr', 'Sake', 'Steve Fox', 'Tekken Force Soldier', 'True Ogre', 'Victor Chevalier', 'Violet', 'Wang Jinrei', 'Yoshimitsu', 'Zafina']\n"
     ]
    }
   ],
   "source": [
    "all_tekken_characters = sorted(all_tekken_characters)\n",
    "print(all_tekken_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "022cc790-5b55-4f23-a859-d4bc3d6afec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tekken_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abfc1886-d163-4624-be50-d3f7f7191cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alex', 'Alisa', 'Bosconovich', 'Angel', 'Anna', 'Williams', 'Armor', 'King', 'Asuka', 'Kazama', 'Ayane', 'Azazel', 'Azucena', 'Ortiz', 'Baek', 'Doo', 'San', 'Bruce', 'Irvin', 'Bryan', 'Fury', 'Christie', 'Monteiro', 'Claudio', 'Serafino', 'Combot', 'Cyclops', 'Debug', 'Devil', 'Jin', 'Doctor', 'Bosconovitch', 'Dragunov,', 'Sergei', 'Eddy', 'Gordo', 'Eddy', 'Gordo', 'Eliza', 'Fahkumram', 'Feng', 'Wei', 'Forest', 'Law', 'Ganryu', 'Geese', 'Howard', 'Gigas', 'Gon', 'Heihachi', 'Mishima', 'Hwoarang', 'Jack', 'Jack-7', 'Jack-8', 'Jin', 'Kazama', 'Jinpachi', 'Mishima', 'Josie', 'Rizal', 'Julia', 'Chang', 'Jun', 'Kazama', 'Katarina', 'Alves', 'Kazumi', 'Mishima', 'King', 'Kuma', 'Kunimitsu', 'Lee', 'Chaolan', 'Leo', 'Kliesen', 'Leroy', 'Smith', 'Lidia', 'Sobieska', 'Lili', 'De', 'Rochefort', 'Ling', 'Xiaoyu', 'Lucky', 'Chloe', 'Marshall', 'Law', 'Master', 'Raven', 'Michelle', 'Chang', 'Miguel', 'Rojo', 'Mokujin', 'Nancy-MI847J', 'Negan', 'Nina', 'Williams', 'Noctis', 'Ogre', 'Panda', 'Paul', 'Phoenix', 'Rachel', 'Reina', 'Roger', 'Jr', 'Sake', 'Steve', 'Fox', 'Tekken', 'Force', 'Soldier', 'True', 'Ogre', 'Victor', 'Chevalier', 'Violet', 'Wang', 'Jinrei', 'Yoshimitsu', 'Zafina']\n"
     ]
    }
   ],
   "source": [
    "characters_split_names = []\n",
    "for index, character in enumerate(all_tekken_characters):\n",
    "    split_name = character.split(\" \")\n",
    "    characters_split_names.extend(split_name)\n",
    "\n",
    "print(characters_split_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67bf79b4-2e0a-4b19-ad1a-7c23f770b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alex', 'alisa', 'bosconovich', 'angel', 'anna', 'williams', 'armor', 'king', 'asuka', 'kazama', 'ayane', 'azazel', 'azucena', 'ortiz', 'baek', 'doo', 'san', 'bruce', 'irvin', 'bryan', 'fury', 'christie', 'monteiro', 'claudio', 'serafino', 'combot', 'cyclops', 'debug', 'devil', 'jin', 'doctor', 'bosconovitch', 'dragunov,', 'sergei', 'eddy', 'gordo', 'eddy', 'gordo', 'eliza', 'fahkumram', 'feng', 'wei', 'forest', 'law', 'ganryu', 'geese', 'howard', 'gigas', 'gon', 'heihachi', 'mishima', 'hwoarang', 'jack', 'jack-7', 'jack-8', 'jin', 'kazama', 'jinpachi', 'mishima', 'josie', 'rizal', 'julia', 'chang', 'jun', 'kazama', 'katarina', 'alves', 'kazumi', 'mishima', 'king', 'kuma', 'kunimitsu', 'lee', 'chaolan', 'leo', 'kliesen', 'leroy', 'smith', 'lidia', 'sobieska', 'lili', 'de', 'rochefort', 'ling', 'xiaoyu', 'lucky', 'chloe', 'marshall', 'law', 'master', 'raven', 'michelle', 'chang', 'miguel', 'rojo', 'mokujin', 'nancy-mi847j', 'negan', 'nina', 'williams', 'noctis', 'ogre', 'panda', 'paul', 'phoenix', 'rachel', 'reina', 'roger', 'jr', 'sake', 'steve', 'fox', 'tekken', 'force', 'soldier', 'true', 'ogre', 'victor', 'chevalier', 'violet', 'wang', 'jinrei', 'yoshimitsu', 'zafina']\n"
     ]
    }
   ],
   "source": [
    "characters_lower = []\n",
    "for i in characters_split_names:\n",
    "    lower_cased_name = i.lower()\n",
    "    characters_lower.append(lower_cased_name)\n",
    "print(characters_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a12be26-1c71-46f8-a4a0-80b818eca234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b80c2b3d-60cd-4ec2-84e5-e8f07e03fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tekken_character_names_from_tokens(tokens: list):\n",
    "    \"\"\"Removes Tekken character names from the comments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        The input dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    tokens_without_character_names = []\n",
    "    \n",
    "    tekken_character_names = ['alex', 'alisa', 'bosconovich', 'angel', 'anna', 'williams', 'armor', 'king', 'asuka', 'kazama', 'ayane', \n",
    "                              'azazel', 'azucena', 'bob', 'Richard', 'ortiz', 'baek', 'doo', 'san', 'bruce', 'irvin', 'bryan', 'fury', 'christie', \n",
    "                              'monteiro', 'claudio', 'serafino', 'combot', 'cyclops', 'debug', 'devil', 'jin', 'doctor', \n",
    "                              'bosconovitch', 'dragunov,', 'sergei', 'eddy', 'gordo', 'eddy', 'gordo', 'eliza', 'fahkumram', 'feng', 'wei', 'forest', \n",
    "                              'law', 'ganryu', 'geese', 'howard', 'gigas', 'gon', 'heihachi', 'mishima', 'hwoarang', 'jack', 'jack-7', \n",
    "                              'jack-8', 'jin', 'kazama', 'jinpachi', 'pachi', 'mishima', 'josie', 'rizal', 'julia', 'chang', 'jun', 'kazama', \n",
    "                              'katarina', 'alves', 'kazumi', 'mishima', 'king', 'kuma', 'kunimitsu', 'lee', 'chaolan', 'leo','kliesen', \n",
    "                              'leroy', 'smith', 'lidia', 'sobieska', 'lili', 'de', 'rochefort', 'ling', 'xiaoyu', 'lucky', 'chloe', \n",
    "                              'marshall', 'law', 'master', 'raven', 'michelle', 'chang', 'miguel', 'rojo', 'mokujin', 'nancy-mi847j', \n",
    "                              'negan', 'nina', 'williams', 'noctis', 'ogre', 'panda', 'paul', 'phoenix', 'rachel', 'reina', 'roger', 'jr', \n",
    "                              'sake', 'steve', 'fox', 'tekken', 'force', 'soldier', 'true', 'ogre', 'trueogre', 'victor', 'chevalier', 'violet', \n",
    "                              'wang', 'jinrei', 'yoshimitsu', \"yoshi\", 'zafina', 'lei', 'wulong', 'craig', 'marduk']\n",
    "\n",
    "    \n",
    "    filtered_tokens = [word for word in tokens if word not in tekken_character_names]\n",
    "    \n",
    "    tokens_without_character_names.extend(filtered_tokens)\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9aebddd7-86ba-4463-8797-5f1521d45241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "      <th>textStopWordsRemoved</th>\n",
       "      <th>textTokenized</th>\n",
       "      <th>textLemmatized</th>\n",
       "      <th>textTekkenCharactersRemoved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>first now where is lei wulong</td>\n",
       "      <td>lei wulong</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>already seen it you are getting less views now bamco</td>\n",
       "      <td>seen getting views bamco</td>\n",
       "      <td>[seen, getting, views, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "      <td>wow</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>i hope we get an angel version of jin</td>\n",
       "      <td>hope angel version jin</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, version]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                            textDisplay  \\\n",
       "0                         first now where is lei wulong   \n",
       "1  already seen it you are getting less views now bamco   \n",
       "2                                                   wow   \n",
       "3                                             oww yeaah   \n",
       "4                 i hope we get an angel version of jin   \n",
       "\n",
       "       textStopWordsRemoved                  textTokenized  \\\n",
       "0                lei wulong                  [lei, wulong]   \n",
       "1  seen getting views bamco  [seen, getting, views, bamco]   \n",
       "2                       wow                          [wow]   \n",
       "3                 oww yeaah                   [oww, yeaah]   \n",
       "4    hope angel version jin    [hope, angel, version, jin]   \n",
       "\n",
       "                textLemmatized textTekkenCharactersRemoved  \n",
       "0                [lei, wulong]                          []  \n",
       "1      [see, get, view, bamco]     [see, get, view, bamco]  \n",
       "2                        [wow]                       [wow]  \n",
       "3                 [oww, yeaah]                [oww, yeaah]  \n",
       "4  [hope, angel, version, jin]             [hope, version]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[\"textTekkenCharactersRemoved\"] = df_processed[\"textLemmatized\"].apply(remove_character_names_from_tokens)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344cce6-64ad-44b0-9f14-f75dd7aba9cd",
   "metadata": {},
   "source": [
    "# Parts of Speech - \n",
    "### tagging, dependency, shape, is_alpha, is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee453e8-2ad2-4fd7-b9df-db5f41bd6c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def part_of_speech(text):\n",
    "    \"\"\"Uses spaCy to return the simple (universal) Part of Speech tag (noun, adjective, verb etc.) for a given text input.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pos : list\n",
    "        The simple part of speech for each token of the input text.\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac9d0cf-f559-43c0-ba5c-3db2b568962d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def part_of_speech_tag(text):\n",
    "    \"\"\"Uses spaCy to return the detailed part-of-speech tag Part of Speech tag for a given text input.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pos_tags : list\n",
    "        The part of speech tags for each token of the input text.\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [token.tag_ for token in doc]\n",
    "    \n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ad555b-eb43-467f-8c43-9db2efdfb0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def part_of_speech_dependency(text):\n",
    "    \"\"\"Uses spaCy to return the syntactic dependency, i.e. the relation between tokens\n",
    "    for a given text input.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dep_tags : list\n",
    "        The dependency tags for each token of the input text.\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    dep_tags = [token.dep_ for token in doc]\n",
    "    \n",
    "    return dep_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051b5c42-6ddd-4b47-ab83-0f44fba1cb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def part_of_speech_shape(text):\n",
    "    \"\"\"Uses spaCy to return the word shape – capitalization, punctuation, digits.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    shape : list\n",
    "        The shape of the token e.g., xxxxx for lower case (e.g., apple), Xxxxx for capital followed \n",
    "        by 4 lower case characters (e.g., Apple), X.X. for something like U.K.\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    shape = [token.shape_ for token in doc]\n",
    "    \n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f617b6-a91e-4e3a-93fb-85ccc6ef0bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def part_of_speech_alpha(text):\n",
    "    \"\"\"Uses spaCy to return a boolean value indicating whether the token is an alphanumeric character.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alpha : list\n",
    "        The dependency tags for each token of the input text.\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    alpha = [token.is_alpha for token in doc]\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1ecdfa-6b02-453e-963f-141f3c37855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def part_of_speech_is_stop(text):\n",
    "    \"\"\"Uses spaCy to return a boolean value indicating if the token is a 'stop word'.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stop_word : list\n",
    "        A true or false value dependent on whether the word is or is not a stop word.\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    stop_word = [token.is_stop for token in doc]\n",
    "    \n",
    "    return stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b879e1c-6712-4cce-b0d0-7d238cccf16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_speech_entity_type(text):\n",
    "    \"\"\"Uses spaCy to return the entity type of each word.\n",
    "\n",
    "    NOTE: \"nlp = spacy.load(\"en_core_web_sm\")\" needs to be defined outside of the function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A string of text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    entity_type : list\n",
    "        The entity type of the word e.g., 'DATE', \n",
    "    \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    entity_type = [token.ent_type_ for token in doc]\n",
    "    \n",
    "    return entity_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323433a-72ab-4bd1-a67d-206548f7471e",
   "metadata": {},
   "source": [
    "# Create dataframe with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05d882a1-758d-4833-8ec6-0621f1964df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "      <th>textStopWordsRemoved</th>\n",
       "      <th>textTokenized</th>\n",
       "      <th>textLemmatized</th>\n",
       "      <th>pos</th>\n",
       "      <th>posTag</th>\n",
       "      <th>posDependency</th>\n",
       "      <th>posShape</th>\n",
       "      <th>posAlpha</th>\n",
       "      <th>posStopWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>first now where is lei wulong</td>\n",
       "      <td>lei wulong</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[PROPN, NOUN]</td>\n",
       "      <td>[NNP, NN]</td>\n",
       "      <td>[compound, ROOT]</td>\n",
       "      <td>[xxx, xxxx]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>already seen it you are getting less views now bamco</td>\n",
       "      <td>seen getting views bamco</td>\n",
       "      <td>[seen, getting, views, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "      <td>[VERB, VERB, NOUN, NOUN]</td>\n",
       "      <td>[VBN, VBG, NNS, NNS]</td>\n",
       "      <td>[ROOT, xcomp, dobj, dobj]</td>\n",
       "      <td>[xxxx, xxxx, xxxx, xxxx]</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "      <td>wow</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[INTJ]</td>\n",
       "      <td>[UH]</td>\n",
       "      <td>[ROOT]</td>\n",
       "      <td>[xxx]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP]</td>\n",
       "      <td>[compound, ROOT]</td>\n",
       "      <td>[xxx, xxxx]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>i hope we get an angel version of jin</td>\n",
       "      <td>hope angel version jin</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[compound, compound, compound, ROOT]</td>\n",
       "      <td>[xxxx, xxxx, xxxx, xxx]</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                            textDisplay  \\\n",
       "0                         first now where is lei wulong   \n",
       "1  already seen it you are getting less views now bamco   \n",
       "2                                                   wow   \n",
       "3                                             oww yeaah   \n",
       "4                 i hope we get an angel version of jin   \n",
       "\n",
       "       textStopWordsRemoved                  textTokenized  \\\n",
       "0                lei wulong                  [lei, wulong]   \n",
       "1  seen getting views bamco  [seen, getting, views, bamco]   \n",
       "2                       wow                          [wow]   \n",
       "3                 oww yeaah                   [oww, yeaah]   \n",
       "4    hope angel version jin    [hope, angel, version, jin]   \n",
       "\n",
       "                textLemmatized                           pos  \\\n",
       "0                [lei, wulong]                 [PROPN, NOUN]   \n",
       "1      [see, get, view, bamco]      [VERB, VERB, NOUN, NOUN]   \n",
       "2                        [wow]                        [INTJ]   \n",
       "3                 [oww, yeaah]                [PROPN, PROPN]   \n",
       "4  [hope, angel, version, jin]  [PROPN, PROPN, PROPN, PROPN]   \n",
       "\n",
       "                 posTag                         posDependency  \\\n",
       "0             [NNP, NN]                      [compound, ROOT]   \n",
       "1  [VBN, VBG, NNS, NNS]             [ROOT, xcomp, dobj, dobj]   \n",
       "2                  [UH]                                [ROOT]   \n",
       "3            [NNP, NNP]                      [compound, ROOT]   \n",
       "4  [NNP, NNP, NNP, NNP]  [compound, compound, compound, ROOT]   \n",
       "\n",
       "                   posShape                  posAlpha  \\\n",
       "0               [xxx, xxxx]              [True, True]   \n",
       "1  [xxxx, xxxx, xxxx, xxxx]  [True, True, True, True]   \n",
       "2                     [xxx]                    [True]   \n",
       "3               [xxx, xxxx]              [True, True]   \n",
       "4   [xxxx, xxxx, xxxx, xxx]  [True, True, True, True]   \n",
       "\n",
       "                    posStopWord  \n",
       "0                [False, False]  \n",
       "1  [False, False, False, False]  \n",
       "2                       [False]  \n",
       "3                [False, False]  \n",
       "4  [False, False, False, False]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_processed[\"pos\"], \n",
    " df_processed[\"posTag\"],\n",
    " df_processed[\"posDependency\"],\n",
    " df_processed[\"posShape\"],\n",
    " df_processed[\"posAlpha\"],\n",
    " df_processed[\"posStopWord\"]) = (df_processed[\"textStopWordsRemoved\"].apply(part_of_speech),\n",
    "                                 df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_tag),\n",
    "                                 df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_dependency),\n",
    "                                 df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_shape),\n",
    "                                 df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_alpha),\n",
    "                                 df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_is_stop)\n",
    "                                )\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f09f65ac-7c9b-44c6-b195-989cb4eaf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(\"data/processed/new_character_reveal_processed.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c0623-dbd3-4d20-be6e-c25418fbfb54",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ae2d9-2d2a-47a9-b8f5-d128a98b7284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_processed[\"pos\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839c7e7-5e10-4ff7-a741-3f85e1b6aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spacy.explain(\"PROPN\"))\n",
    "print(spacy.explain(\"INTJ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ce49c-5ad7-4cd4-a620-715858c70f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_processed[\"posTag\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_tag)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fda81-a3c3-41e7-be4d-067db1ed3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spacy.explain(\"NN\"))\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(spacy.explain(\"NNS\"))\n",
    "print(spacy.explain(\"UH\"))\n",
    "print(spacy.explain(\"VBG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63843b4d-d89a-466c-ac87-f5e55ddf7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"posDependency\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_dependency)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ad756-28f3-4280-9258-b4441f644e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spacy.explain(\"compound\"))\n",
    "print(spacy.explain(\"ROOT\"))\n",
    "print(spacy.explain(\"xcomp\"))\n",
    "print(spacy.explain(\"dobj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b9146-577b-42b9-842d-e13fa3069eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"posShape\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_shape)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb96ec-4a9a-4e8a-aacf-a2008ebdb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"posAlpha\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_alpha)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95feba-432e-4da6-8729-4a6f8cb7a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"posStopWord\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_is_stop)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "831c53ab-bb80-4d52-9210-552f48cd3610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorDisplayName</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>totalReplyCount</th>\n",
       "      <th>textDisplay</th>\n",
       "      <th>textStopWordsRemoved</th>\n",
       "      <th>textTokenized</th>\n",
       "      <th>textLemmatized</th>\n",
       "      <th>pos</th>\n",
       "      <th>posTag</th>\n",
       "      <th>posDependency</th>\n",
       "      <th>posShape</th>\n",
       "      <th>posAlpha</th>\n",
       "      <th>posStopWord</th>\n",
       "      <th>textEntityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@silveriver9</td>\n",
       "      <td>2023-11-01 16:09:58+00:00</td>\n",
       "      <td>2023-11-01 16:10:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>first now where is lei wulong</td>\n",
       "      <td>lei wulong</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[lei, wulong]</td>\n",
       "      <td>[PROPN, NOUN]</td>\n",
       "      <td>[NNP, NN]</td>\n",
       "      <td>[compound, ROOT]</td>\n",
       "      <td>[xxx, xxxx]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[False, False]</td>\n",
       "      <td>[, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@faizaanjaved7150</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>already seen it you are getting less views now bamco</td>\n",
       "      <td>seen getting views bamco</td>\n",
       "      <td>[seen, getting, views, bamco]</td>\n",
       "      <td>[see, get, view, bamco]</td>\n",
       "      <td>[VERB, VERB, NOUN, NOUN]</td>\n",
       "      <td>[VBN, VBG, NNS, NNS]</td>\n",
       "      <td>[ROOT, xcomp, dobj, dobj]</td>\n",
       "      <td>[xxxx, xxxx, xxxx, xxxx]</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@TS-rw4lk</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>2023-11-01 16:10:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow</td>\n",
       "      <td>wow</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[INTJ]</td>\n",
       "      <td>[UH]</td>\n",
       "      <td>[ROOT]</td>\n",
       "      <td>[xxx]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@ALONCAK</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>oww yeaah</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[oww, yeaah]</td>\n",
       "      <td>[PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP]</td>\n",
       "      <td>[compound, ROOT]</td>\n",
       "      <td>[xxx, xxxx]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[False, False]</td>\n",
       "      <td>[PERSON, PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rDxrpSqYHD8</td>\n",
       "      <td>@Rough_Estimates</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>2023-11-01 16:10:06+00:00</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>i hope we get an angel version of jin</td>\n",
       "      <td>hope angel version jin</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[hope, angel, version, jin]</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[compound, compound, compound, ROOT]</td>\n",
       "      <td>[xxxx, xxxx, xxxx, xxx]</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  authorDisplayName                publishedAt  \\\n",
       "0  rDxrpSqYHD8       @silveriver9  2023-11-01 16:09:58+00:00   \n",
       "1  rDxrpSqYHD8  @faizaanjaved7150  2023-11-01 16:10:05+00:00   \n",
       "2  rDxrpSqYHD8          @TS-rw4lk  2023-11-01 16:10:05+00:00   \n",
       "3  rDxrpSqYHD8           @ALONCAK  2023-11-01 16:10:06+00:00   \n",
       "4  rDxrpSqYHD8   @Rough_Estimates  2023-11-01 16:10:06+00:00   \n",
       "\n",
       "                   updatedAt  likeCount  totalReplyCount  \\\n",
       "0  2023-11-01 16:10:43+00:00          4                4   \n",
       "1  2023-11-01 16:10:05+00:00          1                1   \n",
       "2  2023-11-01 16:10:05+00:00          0                0   \n",
       "3  2023-11-01 16:10:06+00:00          0                0   \n",
       "4  2023-11-01 16:10:06+00:00        135               14   \n",
       "\n",
       "                                            textDisplay  \\\n",
       "0                         first now where is lei wulong   \n",
       "1  already seen it you are getting less views now bamco   \n",
       "2                                                   wow   \n",
       "3                                             oww yeaah   \n",
       "4                 i hope we get an angel version of jin   \n",
       "\n",
       "       textStopWordsRemoved                  textTokenized  \\\n",
       "0                lei wulong                  [lei, wulong]   \n",
       "1  seen getting views bamco  [seen, getting, views, bamco]   \n",
       "2                       wow                          [wow]   \n",
       "3                 oww yeaah                   [oww, yeaah]   \n",
       "4    hope angel version jin    [hope, angel, version, jin]   \n",
       "\n",
       "                textLemmatized                           pos  \\\n",
       "0                [lei, wulong]                 [PROPN, NOUN]   \n",
       "1      [see, get, view, bamco]      [VERB, VERB, NOUN, NOUN]   \n",
       "2                        [wow]                        [INTJ]   \n",
       "3                 [oww, yeaah]                [PROPN, PROPN]   \n",
       "4  [hope, angel, version, jin]  [PROPN, PROPN, PROPN, PROPN]   \n",
       "\n",
       "                 posTag                         posDependency  \\\n",
       "0             [NNP, NN]                      [compound, ROOT]   \n",
       "1  [VBN, VBG, NNS, NNS]             [ROOT, xcomp, dobj, dobj]   \n",
       "2                  [UH]                                [ROOT]   \n",
       "3            [NNP, NNP]                      [compound, ROOT]   \n",
       "4  [NNP, NNP, NNP, NNP]  [compound, compound, compound, ROOT]   \n",
       "\n",
       "                   posShape                  posAlpha  \\\n",
       "0               [xxx, xxxx]              [True, True]   \n",
       "1  [xxxx, xxxx, xxxx, xxxx]  [True, True, True, True]   \n",
       "2                     [xxx]                    [True]   \n",
       "3               [xxx, xxxx]              [True, True]   \n",
       "4   [xxxx, xxxx, xxxx, xxx]  [True, True, True, True]   \n",
       "\n",
       "                    posStopWord    textEntityType  \n",
       "0                [False, False]              [, ]  \n",
       "1  [False, False, False, False]          [, , , ]  \n",
       "2                       [False]                []  \n",
       "3                [False, False]  [PERSON, PERSON]  \n",
       "4  [False, False, False, False]          [, , , ]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[\"textEntityType\"] = df_processed[\"textStopWordsRemoved\"].apply(part_of_speech_entity_type)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f6417-dd0c-411e-97e5-dfb35933b17b",
   "metadata": {},
   "source": [
    "Entity type doesn't seem to work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00734369-0bb2-4cdf-8786-39aefe70a725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcc284-9e70-40f3-a967-cb2baa6ed9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35af19-e5ca-45dc-ab37-9a8830fd1705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
